!pip uninstall -y whisper
!pip install -q faster-whisper
!pip install -U google-generativeai


from google.colab import files

print("ðŸ“¤ Upload your podcast audio file (MP3/WAV)")
uploaded = files.upload()

audio_path = list(uploaded.keys())[0]
print("âœ… Uploaded file:", audio_path)


from faster_whisper import WhisperModel

whisper_model = WhisperModel(
    "base",               # same model size as before
    device="cpu",         # change to "cuda" if GPU available
    compute_type="int8"   # fast + memory efficient
)

print("âœ… Fast Whisper model loaded successfully")


segments, info = whisper_model.transcribe(
    audio_path,
    beam_size=5,
    word_timestamps=True
)

print("âœ… Transcription completed")
print("Detected language:", info.language)


result = {
    "segments": [],
    "text": ""
}

for seg in segments:
    result["segments"].append({
        "start": seg.start,
        "end": seg.end,
        "text": seg.text
    })
    result["text"] += seg.text + " "

print(f"Total segments: {len(result['segments'])}")


full_transcript = result["text"].strip()

with open("full_transcript.txt", "w", encoding="utf-8") as f:
    f.write(full_transcript)

print("âœ… Full transcript saved")

files.download("full_transcript.txt")


chunks = []
MAX_DURATION = 120  # seconds

segments = result["segments"]

current_chunk = {
    "start": segments[0]["start"],
    "end": segments[0]["end"],
    "text": segments[0]["text"]
}

for segment in segments[1:]:
    if segment["end"] - current_chunk["start"] <= MAX_DURATION:
        current_chunk["text"] += " " + segment["text"]
        current_chunk["end"] = segment["end"]
    else:
        chunks.append(current_chunk)
        current_chunk = {
            "start": segment["start"],
            "end": segment["end"],
            "text": segment["text"]
        }

chunks.append(current_chunk)

print(f"âœ… Chunks created: {len(chunks)}")


import google.generativeai as genai

# ðŸ”‘ ADD YOUR API KEY HERE
genai.configure(api_key="ADD YOUR API KEY HERE")

llm_model = genai.GenerativeModel("models/gemini-2.5-flash")
print("âœ… Gemini model initialized")


chunks_text = ""

for i, c in enumerate(chunks, 1):
    chunks_text += f"""
Segment {i}
Start Time: {int(c['start'])}s
End Time: {int(c['end'])}s
Text:
{c['text']}
"""


prompt = f"""
You are an NLP expert.

For each segment below, generate:
- Topic Title
- Start Time (hh:mm:ss)
- End Time (hh:mm:ss)
- 4â€“6 Keywords
- Short Summary (2â€“3 lines)

Use EXACTLY this format:

Segment X
Title:
Start Time:
End Time:
Keywords:
Summary:

Segments:
{chunks_text}
"""


response = llm_model.generate_content(prompt)
structured_output = response.text

print(structured_output)


with open("topic_wise_transcript.txt", "w", encoding="utf-8") as f:
    f.write(structured_output)

print("âœ… topic_wise_transcript.txt saved")

files.download("topic_wise_transcript.txt")


import re
import json

def parse_structured_output(text):
    segments = []
    blocks = re.split(r"\n(?=Segment \d+)", text.strip())

    for block in blocks:
        segment = {}

        seg_match = re.search(r"(Segment \d+)", block)
        title = re.search(r"Title:\s*(.*)", block)
        start = re.search(r"Start Time:\s*(.*)", block)
        end = re.search(r"End Time:\s*(.*)", block)
        keywords = re.search(r"Keywords:\s*(.*)", block)
        summary = re.search(r"Summary:\s*(.*)", block, re.S)

        if seg_match:
            segment["segment"] = seg_match.group(1)
        if title:
            segment["title"] = title.group(1).strip()
        if start:
            segment["start_time"] = start.group(1).strip()
        if end:
            segment["end_time"] = end.group(1).strip()
        if keywords:
            segment["keywords"] = [k.strip() for k in keywords.group(1).split(",")]
        if summary:
            segment["summary"] = summary.group(1).strip()

        segments.append(segment)

    return segments

topic_json = parse_structured_output(structured_output)


with open("topic_wise_transcript.json", "w", encoding="utf-8") as f:
    json.dump(topic_json, f, indent=2, ensure_ascii=False)

print("âœ… topic_wise_transcript.json created")

files.download("topic_wise_transcript.json")

