import streamlit as st
import tempfile
import os
import re

from faster_whisper import WhisperModel
import google.generativeai as genai

# ================== CONFIG ==================
st.set_page_config(
    page_title="AI Podcast Topic Navigator",
    layout="wide",
    page_icon="üéôÔ∏è"
)

# ================== STYLES ==================
st.markdown("""
<style>
.stButton>button { width: 100%; border-radius: 20px; border: 1px solid #ff4b4b; }
.stButton>button:hover { background-color: #ff4b4b; color: white; }
.segment-card {
    padding: 15px; border-radius: 10px; background: white;
    border-left: 5px solid #ff4b4b; margin-bottom: 8px;
    box-shadow: 2px 2px 6px rgba(0,0,0,0.05);
}
.keyword-tag {
    display: inline-block; background: #f0f2f6; border-radius: 10px;
    padding: 2px 8px; margin: 2px; font-size: 0.75rem;
    font-weight: bold; color: #ff4b4b;
}
</style>
""", unsafe_allow_html=True)

# ================== HELPERS ==================
def convert_to_seconds(time_str):
    p = time_str.split(":")
    if len(p) == 2:
        return int(p[0]) * 60 + int(p[1])
    if len(p) == 3:
        return int(p[0]) * 3600 + int(p[1]) * 60 + int(p[2])
    return 0

def parse_llm_output(text):
    segments = []
    blocks = re.split(r"\n(?=Segment \d+)", text.strip())

    for block in blocks:
        seg = {
            "segment": re.search(r"(Segment \d+)", block).group(1),
            "title": re.search(r"Title:\s*(.*)", block).group(1),
            "start_time": re.search(r"Start Time:\s*(.*)", block).group(1),
            "end_time": re.search(r"End Time:\s*(.*)", block).group(1),
            "keywords": [k.strip() for k in re.search(r"Keywords:\s*(.*)", block).group(1).split(",")],
            "summary": re.search(r"Summary:\s*(.*)", block, re.S).group(1).strip()
        }
        segments.append(seg)

    return segments

# ================== SESSION STATE ==================
if "segments" not in st.session_state:
    st.session_state.segments = None
if "transcript" not in st.session_state:
    st.session_state.transcript = ""
if "current_time" not in st.session_state:
    st.session_state.current_time = 0
if "show_transcript" not in st.session_state:
    st.session_state.show_transcript = False

# ================== API KEY (HIDDEN) ==================
API_KEY = os.getenv("GEMINI_API_KEY")
if not API_KEY:
    st.error("Gemini API key not found. Please set GEMINI_API_KEY as an environment variable.")
    st.stop()

# ================== SIDEBAR ==================
with st.sidebar:
    st.title("üéß Upload Podcast")
    uploaded_audio = st.file_uploader(
        "Drag & Drop MP3 / WAV",
        type=["mp3", "wav"]
    )
    process_btn = st.button("üöÄ Process Podcast")

# ================== PROCESSING ==================
if process_btn and uploaded_audio:
    with st.spinner("‚è≥ Transcribing & analyzing podcast..."):

        # Save audio temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
            tmp.write(uploaded_audio.read())
            audio_path = tmp.name

        # Fast Whisper
        whisper = WhisperModel("base", device="cpu", compute_type="int8")
        fw_segments, _ = whisper.transcribe(audio_path, word_timestamps=True)

        transcript = ""
        raw_segments = []

        for s in fw_segments:
            transcript += s.text + " "
            raw_segments.append({
                "start": s.start,
                "end": s.end,
                "text": s.text
            })

        st.session_state.transcript = transcript

        # Chunking (2 minutes)
        MAX = 120
        chunks = []
        current = raw_segments[0]

        for seg in raw_segments[1:]:
            if seg["end"] - current["start"] <= MAX:
                current["text"] += " " + seg["text"]
                current["end"] = seg["end"]
            else:
                chunks.append(current)
                current = seg

        chunks.append(current)

        # Gemini
        genai.configure(api_key=API_KEY)
        model = genai.GenerativeModel("models/gemini-2.5-flash")

        chunk_text = ""
        for i, c in enumerate(chunks, 1):
            chunk_text += f"""
Segment {i}
Start Time: {int(c['start'])}s
End Time: {int(c['end'])}s
Text:
{c['text']}
"""

        prompt = f"""
You are an NLP expert.

For each segment below, generate:
- Topic Title
- Start Time (hh:mm:ss)
- End Time (hh:mm:ss)
- 4‚Äì6 Keywords
- Short Summary (2‚Äì3 lines)

Use EXACTLY this format:

Segment X
Title:
Start Time:
End Time:
Keywords:
Summary:

Segments:
{chunk_text}
"""

        response = model.generate_content(prompt)
        st.session_state.segments = parse_llm_output(response.text)

        st.success("‚úÖ Podcast processed successfully!")

# ================== UI OUTPUT ==================
if st.session_state.segments:

    st.title("üéôÔ∏è AI Podcast Topic Navigator")

    st.audio(uploaded_audio, start_time=st.session_state.current_time)

    col1, col2 = st.columns([1, 1], gap="large")

    # -------- LEFT: TOPIC SEGMENTS --------
    with col1:
        st.subheader("üß© Topic Segments")
        st.metric("Total Segments", len(st.session_state.segments))

        for i, seg in enumerate(st.session_state.segments):
            keywords = "".join(
                f"<span class='keyword-tag'>#{k}</span>" for k in seg["keywords"]
            )

            st.markdown(f"""
            <div class="segment-card">
                <b>{seg['start_time']}</b> ‚Äî {seg['title']}
                <br><small>{seg['summary']}</small>
                <div style="margin-top:8px">{keywords}</div>
            </div>
            """, unsafe_allow_html=True)

            if st.button(f"‚ñ∂ Jump to {seg['start_time']}", key=f"jump_{i}"):
                st.session_state.current_time = convert_to_seconds(seg["start_time"])
                st.rerun()

    # -------- RIGHT: TRANSCRIPT (BUTTON CONTROLLED) --------
    with col2:
        st.subheader("üìú Full Transcript")

        b1, b2 = st.columns(2)
        if b1.button("üìÇ Open Transcript"):
            st.session_state.show_transcript = True
        if b2.button("‚ùå Close Transcript"):
            st.session_state.show_transcript = False

        if st.session_state.show_transcript:
            st.text_area(
                "Transcript",
                value=st.session_state.transcript,
                height=600
            ) ..
