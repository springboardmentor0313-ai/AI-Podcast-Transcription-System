!pip install -q openai-whisper nltk scikit-learn

import whisper
import nltk
from nltk.tokenize import sent_tokenize
from google.colab import files

print("Upload your MP3 file")
uploaded = files.upload()

audio_path = list(uploaded.keys())[0]
print("Uploaded file:", audio_path)

print("Loading Whisper model...")
model = whisper.load_model("base")

print("Transcribing audio... This may take a few minutes.")
result = model.transcribe(audio_path)
transcript = result["text"]

print("\nTranscription completed! First 500 characters:\n")
print(transcript[:50000])

nltk.download('punkt')
nltk.download('punkt_tab')

sentences = sent_tokenize(transcript)
print("\nTotal sentences:", len(sentences))

paragraphs = []
sentences_per_paragraph = 4
for i in range(0, len(sentences), sentences_per_paragraph):
    para = " ".join(sentences[i:i + sentences_per_paragraph])
    paragraphs.append(para)

print("Total paragraphs created:", len(paragraphs))

output_file = audio_path.replace(".mp3", "_paragraphs.txt")
with open(output_file, "w", encoding="utf-8") as f:
    for para in paragraphs:
        f.write(para + "\n\n")

print(f"\nParagraph-formatted transcript saved as {output_file}")

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


vectorizer = TfidfVectorizer(stop_words="english")
tfidf = vectorizer.fit_transform(paragraphs)  # paragraphs from previous step


similarities = []

for i in range(len(paragraphs)-1):
    sim = cosine_similarity(tfidf[i], tfidf[i+1])[0][0]
    similarities.append(sim)

# Display first 10 similarities for reference
print("Cosine similarities between consecutive paragraphs:", similarities[:10])


threshold = 0.45  # lower similarity = likely topic change
topic_boundaries = [i+1 for i, sim in enumerate(similarities) if sim < threshold]

print("Topic boundaries at paragraph numbers:", topic_boundaries)


topics = []
start = 0

for boundary in topic_boundaries:
    topics.append(" ".join(paragraphs[start:boundary]))
    start = boundary

# Add last segment
topics.append(" ".join(paragraphs[start:]))

print("Total topics detected:", len(topics))


output_file = audio_path.replace(".mp3", "_topics.txt")
with open(output_file, "w", encoding="utf-8") as f:
    for i, topic in enumerate(topics, 1):
        f.write(f"--- Topic {i} ---\n")
        f.write(topic + "\n\n")

print(f"Topic segmentation saved as {output_file}")


from google.colab import files
files.download("a6_topics.txt")

# Open the topic segmentation file
with open("a6_topics.txt", "r", encoding="utf-8") as f:
    topics_content = f.read()

# Split by topics (assuming each topic starts with "--- Topic")
topics = topics_content.split('--- Topic ')[1:]  # skip any empty text before first topic

# Print each topic fully
for t in topics:
    lines = t.split('\n', 1)  # first line = topic number
    topic_num = lines[0].strip()
    topic_text = lines[1].strip() if len(lines) > 1 else ""

    print(f"\nðŸ”¹ Topic {topic_num}\n{topic_text}\n")
